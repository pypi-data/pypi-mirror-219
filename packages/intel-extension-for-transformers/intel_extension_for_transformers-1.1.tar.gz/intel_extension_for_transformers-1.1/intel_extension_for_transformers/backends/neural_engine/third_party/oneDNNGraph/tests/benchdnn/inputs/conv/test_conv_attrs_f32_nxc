# f32
--reset --cfg=f32
--mb=2
--stag=axb --dtag=axb
--skip-impl=ref,x64:gemm      # ! test jit version only
--dir=FWD_B
--attr-post-ops=sum+relu --batch=shapes_resnet_50
--attr-post-ops=sum+relu:0.5 --batch=shapes_tails
--attr-post-ops=sum+tanh:0:0:2.5 --batch=shapes_tails
--attr-post-ops=sum+elu:0.5 --batch=shapes_tails
--attr-post-ops=sum+abs --batch=shapes_tails
--attr-post-ops=sum+linear:0.5:1.5 --batch=shapes_tails
--attr-post-ops=sum+bounded_relu:0.5 --batch=shapes_tails
--attr-post-ops=sum+logistic:0:0:2.5 --batch=shapes_tails
--attr-post-ops=sum+square --batch=shapes_tails
--attr-post-ops=sum+soft_relu --batch=shapes_tails
--attr-post-ops=sum+soft_relu_v2:0.5 --batch=shapes_tails
--attr-post-ops=sum+pow:0.5:0.33 --batch=shapes_tails

--attr-post-ops=add:f32:per_oc,add:f32:per_tensor --batch=shapes_tails

--attr-post-ops=prelu:per_oc,sum+prelu:per_oc --batch=shapes_tails

# Same post-op with different alpha/beta
--attr-post-ops=linear:1:2+linear:1:3,linear:2:0+linear:3:0 --batch=shapes_tails
