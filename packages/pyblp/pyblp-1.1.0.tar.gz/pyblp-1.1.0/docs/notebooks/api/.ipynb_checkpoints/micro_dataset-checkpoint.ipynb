{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f45906",
   "metadata": {},
   "source": [
    "# Micro Dataset Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d6b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyblp\n",
    "\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca57169",
   "metadata": {},
   "source": [
    "In this example, we'll build a configuration for a micro dataset. Micro datasets, typically surveys, are independent sources of information that typically relate individual purchases to consumer demographics. For background and notation involving micro moments, see :ref:`background:Micro Moments`.\n",
    "\n",
    "Configuring a micro dataset does not require access to the full micro data. It simply specifies metadata about that dataset that will be used for estimation and for outputting information during estimation. These metadata include a unique name for the dataset indexed by $d$, the number of observations $N_d$, a function that defines survey weights $w_{dijt}$, and if relevant, a subset of markets from which the micro data was sampled.\n",
    "\n",
    "First, we'll define a configuration for the micro dataset used by :ref:`references:Petrin (2002)`, which is also used in the corresponding [tutorial](petrin.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f07f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CEX: 29125 Observations in All Markets"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_dataset = pyblp.MicroDataset(\n",
    "    name=\"CEX\", \n",
    "    observations=29125, \n",
    "    compute_weights=lambda t, p, a: np.ones((a.size, 1 + p.size)),\n",
    ")\n",
    "micro_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47719f2",
   "metadata": {},
   "source": [
    "We called the dataset \"CEX\", defined the number of observations in it, and also defined a lambda function for computing survey weights in a market. Since we did not specify `market_ids`, we are assuming that the underlying micro data were sampled from all markets in the product data.\n",
    "\n",
    "The `compute_weights` function has three arguments: the current market's ID $t$, the $J_t$ :class:`Products` inside the market, and the $I_t$ :class:`Agents` inside the market. In this case, we are assuming that each product and agent/consumer type are sampled with equal probability, so we simply return a matrix of ones of shape $I_t \\times (1 + J_t)$. This sets each $w_{dijt} = 1$.\n",
    "\n",
    "By using $1 + J_t$ instead of $J_t$, we are specifying that the micro dataset contains observations of the outside option $j = 0$. If we instead specified a matrix of shape $I_t \\times (1 + J_t)$, this would be the same as setting the first column equal to all zeros, so that outside choices are not sampled from.\n",
    "\n",
    "Lastly, returning an array with two dimensions means that this micro dataset does not contain second choices. If we were to add a third dimension, for example specifying `lambda t, p, a: np.ones((a.size, 1 + p.size, 1 + p.size))`, we would be configuring the micro dataset to also have information about second choices, including for second choices of the outside option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
