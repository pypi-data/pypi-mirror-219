Metadata-Version: 2.1
Name: mortardata
Version: 0.1.4
Summary: 
License: BSD-3-Clause
Author: Gabe Fierro
Author-email: gtfierro@mines.edu
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: grequests (>=0.7.0,<0.8.0)
Requires-Dist: loguru (>=0.7.0,<0.8.0)
Requires-Dist: pandas (>=2.0.3,<3.0.0)
Requires-Dist: pyarrow (>=12.0.1,<13.0.0)
Requires-Dist: rdflib (>=6.3.2,<7.0.0)
Requires-Dist: requests (>=2.31.0,<3.0.0)
Requires-Dist: tqdm (>=4.65.0,<5.0.0)
Description-Content-Type: text/markdown

# Mortar Data (Serverless)

Install with `pip install mortardata`

Set the following environment variables:

```bash
export MORTARDATA_S3_REGION=""
export MORTARDATA_S3_BUCKET=""
export MORTARDATA_QUERY_ENDPOINT=""
```

Then use as follows:


```python
from mortardata import Client

c = Client()

all_points = """
PREFIX brick: <https://brickschema.org/schema/Brick#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX ref: <https://brickschema.org/schema/Brick/ref#>
SELECT ?point ?type ?uuid WHERE {
    ?point rdf:type/rdfs:subClassOf* brick:Point ;
           rdf:type ?type ;
           ref:hasExternalReference [ ref:hasTimeseriesId ?uuid ] .
}"""
df = c.sparql(all_points.strip())
df.to_csv("all_points.csv")
print(df.head())

query1 = """
PREFIX brick: <https://brickschema.org/schema/Brick#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX ref: <https://brickschema.org/schema/Brick/ref#>
SELECT ?sen_point ?sen ?equip ?equip_type WHERE {
    ?equip rdf:type ?equip_type .
    ?sen_point rdf:type brick:Supply_Air_Temperature_Sensor ;
               brick:isPointOf ?equip ;
               ref:hasExternalReference [ ref:hasTimeseriesId ?sen ] .
} LIMIT 10"""
df = c.sparql(query1)
df.to_csv("query1_sparql.csv")
print(df.head())

df = c.data_sparql(query1, start="2016-01-01", end="2016-02-01", limit=1e6, sites=['bldg2','bldg5'])
print(df.head())

res = c.data_sparql_to_csv(query1, "query1.csv", sites=['bldg2','bldg5'])
print(res)
```

